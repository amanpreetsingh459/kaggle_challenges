{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "q9AGODg5KQsu"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8833098ae194da992375507f8229aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a9b37f88f7243b39e2c3247019416c2",
              "IPY_MODEL_b9074b6056b44e98805574dbbe4297ba",
              "IPY_MODEL_3ca7cd14d68f4fdd8a05e625ba065207"
            ],
            "layout": "IPY_MODEL_4a20dd345f554aa79e7ccb2f83aef8a6"
          }
        },
        "7a9b37f88f7243b39e2c3247019416c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d144de22936c46e296e12ed55d3345a6",
            "placeholder": "​",
            "style": "IPY_MODEL_21b2732cc05a4c9fb11df061fcbae4bd",
            "value": "Map: 100%"
          }
        },
        "b9074b6056b44e98805574dbbe4297ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c5a8312bea045a8adaedf35eaa20852",
            "max": 52002,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e39f73cc5cc4d30ad4a0004162fe156",
            "value": 52002
          }
        },
        "3ca7cd14d68f4fdd8a05e625ba065207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236520cec069482186151de7403782c1",
            "placeholder": "​",
            "style": "IPY_MODEL_5a1af79b29804a0887d506c319d583c8",
            "value": " 52002/52002 [00:39&lt;00:00, 1402.87 examples/s]"
          }
        },
        "4a20dd345f554aa79e7ccb2f83aef8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d144de22936c46e296e12ed55d3345a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b2732cc05a4c9fb11df061fcbae4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c5a8312bea045a8adaedf35eaa20852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e39f73cc5cc4d30ad4a0004162fe156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "236520cec069482186151de7403782c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1af79b29804a0887d506c319d583c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installation and Imports"
      ],
      "metadata": {
        "id": "q9AGODg5KQsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation (please use latest versions if stucked anywhere)\n",
        "!pip install -q accelerate==0.34.2\n",
        "!pip install -q peft==0.14.0\n",
        "!pip install -q bitsandbytes==0.45.0\n",
        "!pip install -q transformers==4.47.1\n",
        "!pip install -q trl==0.13.0\n",
        "#!pip install -q fastrlock==0.8.2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:11:41.348110Z",
          "iopub.execute_input": "2024-12-29T11:11:41.348395Z",
          "iopub.status.idle": "2024-12-29T11:12:13.051728Z",
          "shell.execute_reply.started": "2024-12-29T11:11:41.348373Z",
          "shell.execute_reply": "2024-12-29T11:12:13.050829Z"
        },
        "id": "Eg0oc7wEBaC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os, torch, logging\n",
        "from datasets import load_dataset, concatenate_datasets, Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    EarlyStoppingCallback)\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:13.053082Z",
          "iopub.execute_input": "2024-12-29T11:12:13.053400Z",
          "iopub.status.idle": "2024-12-29T11:12:28.826005Z",
          "shell.execute_reply.started": "2024-12-29T11:12:13.053366Z",
          "shell.execute_reply": "2024-12-29T11:12:28.825135Z"
        },
        "id": "9cilH6B0BaC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Setup your huggingface login account [link](https://huggingface.co/)\n",
        "- Get the huggingface access token by navigating to `your profile -> Access Tokens -> +Create new token`"
      ],
      "metadata": {
        "id": "ZJvtTlOtCxw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set enironment variables (secrets if working in colab)\n",
        "os.environ['HF_TOKEN'] = '<your-huggingface-token>'\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:28.827629Z",
          "iopub.execute_input": "2024-12-29T11:12:28.827938Z",
          "iopub.status.idle": "2024-12-29T11:12:28.831549Z",
          "shell.execute_reply.started": "2024-12-29T11:12:28.827916Z",
          "shell.execute_reply": "2024-12-29T11:12:28.830771Z"
        },
        "id": "avjM63U-BaC-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Creation/Curation"
      ],
      "metadata": {
        "id": "ipeFLOm0Dlw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca format for the dataset to be arranged in this manner\n",
        "alpaca_prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:28.832931Z",
          "iopub.execute_input": "2024-12-29T11:12:28.833225Z",
          "iopub.status.idle": "2024-12-29T11:12:28.848397Z",
          "shell.execute_reply.started": "2024-12-29T11:12:28.833194Z",
          "shell.execute_reply": "2024-12-29T11:12:28.847532Z"
        },
        "id": "8ccQkwySBaC-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# download the gemma tokenizer and get EOS token\n",
        "gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
        "EOS_TOKEN = gemma_tokenizer.eos_token # Must add EOS_TOKEN\n",
        "EOS_TOKEN"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:11.202523Z",
          "iopub.execute_input": "2024-12-29T00:44:11.202819Z",
          "iopub.status.idle": "2024-12-29T00:44:14.294895Z",
          "shell.execute_reply.started": "2024-12-29T00:44:11.202790Z",
          "shell.execute_reply": "2024-12-29T00:44:14.294199Z"
        },
        "id": "qa6yfkQVBaC_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset formatting function\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        if input is None:\n",
        "            input = \"\"\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:14.303919Z",
          "iopub.execute_input": "2024-12-29T00:44:14.304156Z",
          "iopub.status.idle": "2024-12-29T00:44:14.316916Z",
          "shell.execute_reply.started": "2024-12-29T00:44:14.304136Z",
          "shell.execute_reply": "2024-12-29T00:44:14.316179Z"
        },
        "id": "Am-tcdApBaDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download and preprocess function\n",
        "def process_dataset(dataset_name,\n",
        "                    split_type,\n",
        "                    processing_func,\n",
        "                    rename_column = False,\n",
        "                    filter_data = False,\n",
        "                    filter_column_value = 'id',\n",
        "                    filter_value = 'alpaca',\n",
        "                    num_samples=20000):\n",
        "\n",
        "    if isinstance(dataset_name, str):\n",
        "        dataset = load_dataset(dataset_name, split=split_type)\n",
        "    else:\n",
        "        # Assuming dataset_name is a filepath for JSON file\n",
        "        with open(dataset_name, 'r') as file:\n",
        "            data = []\n",
        "            for line_number, line in enumerate(file, 1):\n",
        "                try:\n",
        "                    data.append(json.loads(line))\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error parsing JSON at line {line_number}: {e}\")\n",
        "            dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
        "\n",
        "    if rename_column:\n",
        "        dataset = rename(dataset)\n",
        "\n",
        "    if filter_data:\n",
        "        dataset = filter_dataset(dataset, num_samples, value, column_name)\n",
        "\n",
        "    dataset = dataset.map(processing_func, batched=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Define the additional processing steps\n",
        "def rename(dataset):\n",
        "    return dataset.rename_column('response', 'output')\n",
        "\n",
        "def filter_dataset(dataset, num_samples, value, column_name):\n",
        "    return dataset.filter(lambda example: value in example[column_name]).shuffle(seed=42).select(range(num_samples))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:14.317787Z",
          "iopub.execute_input": "2024-12-29T00:44:14.318089Z",
          "iopub.status.idle": "2024-12-29T00:44:14.334449Z",
          "shell.execute_reply.started": "2024-12-29T00:44:14.318060Z",
          "shell.execute_reply": "2024-12-29T00:44:14.333775Z"
        },
        "id": "2bGU4F8TBaDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = \"HydraIndicLM/punjabi_alpaca_52K\"\n",
        "dataset = process_dataset(dataset_id, \"train\", formatting_prompts_func)\n",
        "dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:14.335110Z",
          "iopub.execute_input": "2024-12-29T00:44:14.335300Z",
          "iopub.status.idle": "2024-12-29T00:44:20.088584Z",
          "shell.execute_reply.started": "2024-12-29T00:44:14.335282Z",
          "shell.execute_reply": "2024-12-29T00:44:20.087763Z"
        },
        "id": "CFyKGDK9BaDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.to_pandas()\n",
        "df.to_csv(\"dataset.csv\") #save dataset in a csv file"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:20.830188Z",
          "iopub.execute_input": "2024-12-29T00:44:20.830537Z",
          "iopub.status.idle": "2024-12-29T00:44:21.261850Z",
          "shell.execute_reply.started": "2024-12-29T00:44:20.830495Z",
          "shell.execute_reply": "2024-12-29T00:44:21.260996Z"
        },
        "id": "OYwhKyG5BaDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return gemma_tokenizer(examples[\"text\"], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "encoded_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:22.510660Z",
          "iopub.execute_input": "2024-12-29T00:44:22.510908Z",
          "iopub.status.idle": "2024-12-29T00:44:41.144159Z",
          "shell.execute_reply.started": "2024-12-29T00:44:22.510886Z",
          "shell.execute_reply": "2024-12-29T00:44:41.143077Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c8833098ae194da992375507f8229aed",
            "7a9b37f88f7243b39e2c3247019416c2",
            "b9074b6056b44e98805574dbbe4297ba",
            "3ca7cd14d68f4fdd8a05e625ba065207",
            "4a20dd345f554aa79e7ccb2f83aef8a6",
            "d144de22936c46e296e12ed55d3345a6",
            "21b2732cc05a4c9fb11df061fcbae4bd",
            "3c5a8312bea045a8adaedf35eaa20852",
            "6e39f73cc5cc4d30ad4a0004162fe156",
            "236520cec069482186151de7403782c1",
            "5a1af79b29804a0887d506c319d583c8"
          ]
        },
        "id": "4qnCLTzoBaDA",
        "outputId": "e96a9d1e-dbfc-4b7c-9d7e-1f8d4172ea0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8833098ae194da992375507f8229aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'instruction', 'output', 'text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 52002\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset in train, validation and test sets\n",
        "train_dataset = encoded_dataset.select(range(44000))\n",
        "val_dataset = encoded_dataset.select(range(44000, 47000))\n",
        "test_dataset = encoded_dataset.select(range(47000, 52002))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:41.151815Z",
          "iopub.execute_input": "2024-12-29T00:44:41.152232Z",
          "iopub.status.idle": "2024-12-29T00:44:42.037782Z",
          "shell.execute_reply.started": "2024-12-29T00:44:41.152202Z",
          "shell.execute_reply": "2024-12-29T00:44:42.036847Z"
        },
        "id": "s8exllmkBaDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Dataset with \"input_ids\" column\n",
        "train_dataset = Dataset.from_dict({\"input_ids\": train_dataset[\"input_ids\"]})\n",
        "val_dataset = Dataset.from_dict({\"input_ids\": val_dataset[\"input_ids\"]})\n",
        "test_dataset = Dataset.from_dict({\"input_ids\": test_dataset[\"input_ids\"]})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:42.044572Z",
          "iopub.execute_input": "2024-12-29T00:44:42.044767Z",
          "iopub.status.idle": "2024-12-29T00:44:58.005480Z",
          "shell.execute_reply.started": "2024-12-29T00:44:42.044750Z",
          "shell.execute_reply": "2024-12-29T00:44:58.004702Z"
        },
        "id": "aITqYIevBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model fine-tuning"
      ],
      "metadata": {
        "id": "qO_4-yA_FTIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the gemma-2-2b base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2-2b\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:44:58.006315Z",
          "iopub.execute_input": "2024-12-29T00:44:58.006581Z",
          "iopub.status.idle": "2024-12-29T00:49:14.886117Z",
          "shell.execute_reply.started": "2024-12-29T00:44:58.006546Z",
          "shell.execute_reply": "2024-12-29T00:49:14.885226Z"
        },
        "id": "8jwfrWZzBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA Config for fine-tuning\n",
        "peft_parameters = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=8,\n",
        "    bias=\"none\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:49:14.887122Z",
          "iopub.execute_input": "2024-12-29T00:49:14.887524Z",
          "iopub.status.idle": "2024-12-29T00:49:14.891289Z",
          "shell.execute_reply.started": "2024-12-29T00:49:14.887400Z",
          "shell.execute_reply": "2024-12-29T00:49:14.890706Z"
        },
        "id": "j7v6A_4_BaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Params\n",
        "train_params = TrainingArguments(\n",
        "    output_dir=\"./output_dir\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1, #validation\n",
        "    evaluation_strategy=\"steps\", #validation\n",
        "    save_strategy=\"steps\", #validation\n",
        "    metric_for_best_model=\"eval_loss\", #validation\n",
        "    load_best_model_at_end=True, #validation\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=500,\n",
        "    eval_steps=500, #validation\n",
        "    logging_steps=500,\n",
        "    logging_dir=None,\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=1.0,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    save_total_limit=10\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:49:14.894069Z",
          "iopub.execute_input": "2024-12-29T00:49:14.894270Z",
          "iopub.status.idle": "2024-12-29T00:49:16.436384Z",
          "shell.execute_reply.started": "2024-12-29T00:49:14.894252Z",
          "shell.execute_reply": "2024-12-29T00:49:16.435719Z"
        },
        "id": "soEYkBfvBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer to train the model\n",
        "trainer = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=peft_parameters,\n",
        "    args=train_params,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:49:16.437349Z",
          "iopub.execute_input": "2024-12-29T00:49:16.437563Z",
          "iopub.status.idle": "2024-12-29T00:49:18.685240Z",
          "shell.execute_reply.started": "2024-12-29T00:49:16.437543Z",
          "shell.execute_reply": "2024-12-29T00:49:18.684571Z"
        },
        "id": "hBYoJQLVBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# helpful in capturing the validation logs\n",
        "trainer.can_return_loss = True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T00:49:18.686005Z",
          "iopub.execute_input": "2024-12-29T00:49:18.686301Z",
          "iopub.status.idle": "2024-12-29T00:49:18.689940Z",
          "shell.execute_reply.started": "2024-12-29T00:49:18.686270Z",
          "shell.execute_reply": "2024-12-29T00:49:18.689039Z"
        },
        "id": "0mzMqcd5BaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# when you have a few of the training checkpoint saved already\n",
        "#trainer.train(resume_from_checkpoint = True)\n",
        "\n",
        "trainer.train() #start fine-tuning from scratch"
      ],
      "metadata": {
        "trusted": true,
        "id": "rkjyvsS_BaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# get the training log history\n",
        "trainer.state.log_history"
      ],
      "metadata": {
        "trusted": true,
        "id": "FMudJCuGBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "eval_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test results:\", eval_results)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ymvQxf8VBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# saving fine-tuned weights locally\n",
        "trainer.save_model(\"gemma-2-2b-punjabi-finetuned-4\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-DQlqctsBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#push fine-tuned weights(from trainer) to huggingface\n",
        "trainer.push_to_hub(\"amanpreetsingh459/gemma-2-2b-punjabi-finetuned-4\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "FsF79w3GBaDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# save the base-model locally in the same directory\n",
        "base_model.save_pretrained(\"gemma-2-2b-punjabi-finetuned-4\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "gF5mgsOhBaDC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# push the base model to huggingface in the same directory\n",
        "base_model.push_to_hub(\"amanpreetsingh459/gemma-2-2b-punjabi-finetuned-4\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "YXLcH1e7BaDC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# push the tokenizer to huggingface as well\n",
        "gemma_tokenizer.push_to_hub(\"amanpreetsingh459/gemma-2-2b-punjabi-finetuned-4\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "M7SXxCmABaDG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "KZzO0lqoBaDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Use all the imports from above 'Installations and Imports' section*"
      ],
      "metadata": {
        "id": "EjRd61KbfGKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below is the huggingface directory location to load the model from\n",
        "# you can download the model in local and give the location to that as well\n",
        "finetuned_model_name = \"amanpreetsingh459/gemma-2-2b-punjabi-finetuned-4\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:28.849274Z",
          "iopub.execute_input": "2024-12-29T11:12:28.849583Z",
          "iopub.status.idle": "2024-12-29T11:12:28.862538Z",
          "shell.execute_reply.started": "2024-12-29T11:12:28.849549Z",
          "shell.execute_reply": "2024-12-29T11:12:28.861708Z"
        },
        "id": "PVlbUAeiBaDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_name)\n",
        "EOS_TOKEN = gemma_tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:28.863430Z",
          "iopub.execute_input": "2024-12-29T11:12:28.863709Z",
          "iopub.status.idle": "2024-12-29T11:12:33.729862Z",
          "shell.execute_reply.started": "2024-12-29T11:12:28.863680Z",
          "shell.execute_reply": "2024-12-29T11:12:33.728965Z"
        },
        "id": "Vl1d0TypBaDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_finetuned = AutoModelForCausalLM.from_pretrained(\n",
        "    finetuned_model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:12:33.730917Z",
          "iopub.execute_input": "2024-12-29T11:12:33.731152Z",
          "iopub.status.idle": "2024-12-29T11:17:01.286541Z",
          "shell.execute_reply.started": "2024-12-29T11:12:33.731133Z",
          "shell.execute_reply": "2024-12-29T11:17:01.285861Z"
        },
        "id": "U_R1nuy3BaDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "KIHmEDUeJyEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input your instruction here to generate the response\n",
        "instruction = \"ਮੇਨੂ ਏਕ ਕਵਿਤਾ ਲਿੱਖ ਕੇ ਦੇਯੋ ਜੀ\""
      ],
      "metadata": {
        "id": "TD6RL6hRmBlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = gemma_tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        instruction, # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:17:01.288657Z",
          "iopub.execute_input": "2024-12-29T11:17:01.288981Z",
          "iopub.status.idle": "2024-12-29T11:17:01.301758Z",
          "shell.execute_reply.started": "2024-12-29T11:17:01.288956Z",
          "shell.execute_reply": "2024-12-29T11:17:01.301125Z"
        },
        "id": "MYDcHcJHBaDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_finetuned.generate(**inputs, max_new_tokens = 250)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:17:01.302665Z",
          "iopub.execute_input": "2024-12-29T11:17:01.302987Z",
          "iopub.status.idle": "2024-12-29T11:17:11.337892Z",
          "shell.execute_reply.started": "2024-12-29T11:17:01.302956Z",
          "shell.execute_reply": "2024-12-29T11:17:11.337127Z"
        },
        "id": "ZC0bxON_BaDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_outputs = gemma_tokenizer.batch_decode(outputs)\n",
        "print(decoded_outputs[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T11:17:11.338689Z",
          "iopub.execute_input": "2024-12-29T11:17:11.338995Z",
          "iopub.status.idle": "2024-12-29T11:17:11.343689Z",
          "shell.execute_reply.started": "2024-12-29T11:17:11.338965Z",
          "shell.execute_reply": "2024-12-29T11:17:11.343007Z"
        },
        "id": "_FGOi6ygBaDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053b8c97-d59c-40e4-d74f-7082baf42b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos>\n",
            "### Instruction:\n",
            "ਮੇਨੂ ਏਕ ਕਵਿਤਾ ਲਿੱਖ ਕੇ ਦੇਯੋ ਜੀ\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "ਮੇਨੂ ਏਕ ਕਵਿਤਾ ਲਿਖਣਾ ਇੱਕ ਸ਼ਾਨਦਾਰ ਅਨੁਭਵ ਹੈ। ਇਹ ਸ਼ਾਨਦਾਰ ਸੰਗੀਤ ਅਤੇ ਸ਼ਬਦਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਸ਼ਾਨਦਾਰ ਕਵਿਤਾ ਬਣਾਉਣਾ ਹੈ। ਇਹ ਇੱਕ ਸ਼ਾਨਦਾਰ ਸੰਗੀਤ ਸੰਗੀਤ ਅਤੇ ਸ਼ਬਦਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਸ਼ਾਨਦਾਰ ਕਵਿਤਾ ਬਣਾਉਣਾ ਹੈ। ਇਹ ਇੱਕ ਸ਼ਾਨਦਾਰ ਸੰਗੀਤ ਸੰਗੀਤ ਅਤੇ ਸ਼ਬਦਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਸ਼ਾਨਦਾਰ ਕਵਿਤਾ ਬਣਾਉਣਾ ਹੈ। ਇਹ ਇੱਕ ਸ਼ਾਨਦਾਰ ਸੰਗੀਤ ਸੰਗੀਤ ਅਤੇ ਸ਼ਬਦਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਸ਼ਾਨਦਾਰ ਕਵਿਤਾ ਬਣਾਉਣਾ ਹੈ। ਇਹ ਇੱਕ ਸ਼ਾਨਦਾਰ ਸੰਗੀਤ ਸੰਗੀਤ\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metrics"
      ],
      "metadata": {
        "id": "Mil11e3_ZClm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Required installations\n",
        "!pip install --upgrade -q nltk\n",
        "!pip install -q evaluate\n",
        "!pip install -q rouge_score\n",
        "!pip install -q bert_score\n",
        "!pip install -q mauve-text"
      ],
      "metadata": {
        "trusted": true,
        "id": "qc_G-jixBaDI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "from evaluate import load\n",
        "import nltk\n",
        "import os, torch\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0Jx-gWAmZ5gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources if you haven't already\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "tgtv2_0lZ5dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *The prediciton have been generated from the fine-tuned model and kept in the file given at [this github link](https://github.com/amanpreetsingh459/kaggle_challenges/blob/master/google-gemma-2-language-fine-tuning/predictions_test_data.csv)*"
      ],
      "metadata": {
        "id": "KRiYb0lnaQhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_preds_df = pd.read_csv(\"predictions_test_data.csv\")\n",
        "predictions=list(saved_preds_df['predictions'])\n",
        "references=list(saved_preds_df['references'])"
      ],
      "metadata": {
        "id": "2jXQWTpSZ5Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU\n",
        "bleu = load(\"bleu\")\n",
        "bleu_results = bleu.compute(predictions=predictions, references=references)\n",
        "print(f\"BLEU Score: {bleu_results['bleu']}\")\n",
        "\n",
        "## Output\n",
        "#BLEU Score: 0.03157486421394274"
      ],
      "metadata": {
        "id": "-CjpyycoaL4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROUGE\n",
        "rouge = load(\"rouge\")\n",
        "rouge_results = rouge.compute(predictions=predictions, references=references)\n",
        "print(f\"ROUGE Score: {rouge_results}\")  # This will print different ROUGE variants\n",
        "\n",
        "## Output\n",
        "#ROUGE Score: {'rouge1': 0.038499762388349804, 'rouge2': 0.013019296072536182, 'rougeL': 0.03762116227346678, 'rougeLsum': 0.037291436269988584}"
      ],
      "metadata": {
        "id": "3g_1aVPiaLzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-BLEU (This requires a bit more complex logic to compare generated texts to each other)\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def self_bleu(texts):\n",
        "    \"\"\"Calculates the average self-BLEU score of each generated text against all other generated texts.\"\"\"\n",
        "    self_bleu_scores = []\n",
        "    for i in range(len(texts)):\n",
        "        current_text = texts[i].split()  # Tokenize the current text\n",
        "        other_texts = [texts[j].split() for j in range(len(texts)) if j != i]  # Tokenize other texts\n",
        "        bleu_score = sentence_bleu(other_texts, current_text, smoothing_function=SmoothingFunction().method1)\n",
        "        self_bleu_scores.append(bleu_score)\n",
        "    return sum(self_bleu_scores) / len(self_bleu_scores)\n",
        "\n",
        "self_bleu_score = self_bleu(predictions)\n",
        "print(f\"Self-BLEU Score: {self_bleu_score}\")\n",
        "\n",
        "## Output\n",
        "#Self-BLEU Score: 0.4602623690010304"
      ],
      "metadata": {
        "id": "3nThMpMUaLwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Citations"
      ],
      "metadata": {
        "id": "yIMmaK8nimq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bibtex\n",
        "@article{gemma_2024,\n",
        "    title={Gemma},\n",
        "    url={https://www.kaggle.com/m/3301},\n",
        "    DOI={10.34740/KAGGLE/M/3301},\n",
        "    publisher={Kaggle},\n",
        "    author={Gemma Team},\n",
        "    year={2024}\n",
        "}\n",
        "\n",
        "@misc{gemma-language-tuning,\n",
        "    author = {Glenn Cameron and Lauren Usui and Paul Mooney and Addison Howard},\n",
        "    title = {Google - Unlock Global Communication with Gemma},\n",
        "    year = {2024},\n",
        "    howpublished = {\\url{https://kaggle.com/competitions/gemma-language-tuning}},\n",
        "    note = {Kaggle}\n",
        "}\n",
        "\n",
        "@misc{vonwerra2022trl,\n",
        "\ttitle        = {{TRL: Transformer Reinforcement Learning}},\n",
        "\tauthor       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},\n",
        "\tyear         = 2020,\n",
        "\tjournal      = {GitHub repository},\n",
        "\tpublisher    = {GitHub},\n",
        "\thowpublished = {\\url{https://github.com/huggingface/trl}}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "iZjAkVC7i1n-"
      }
    }
  ]
}